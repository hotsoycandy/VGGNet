# VGGNet
VGGNet 구현

## 논문 해석

### 초록

이 논문에서, 우리는 대량의 이미지를 다루는 이미지 분류 합성곱 신경망에서의 층의 깊이에 따른 영향에 대해 연구하였다. 우리의 주요 기여는 아주 작은 합성곱 필터를 사용하는 네트워크의 깊이를 점점 늘려 철저한 평가하는 것이며, 16 - 19 깊이의 층을 사용하여 이전 기술보다 확실한 개선을 보여준다. 이 발견은 우리의 2014 이미지넷 챌린지 제출 자료의 기초가 되었으며, 장소 분류 분야에서 1등, 사물 분류 분야에서 2등을 달성하였다. 우리는 우리의 결과물이 다른 데이터에도 일반화가 잘 되어 있다는 것을 보여주며, 최첨단의 결과물이다.

### 1. 서론

최근, 합성곱 계층은 대규모 공개 이미지 저장소 ImageNet나 GPU 클러스터링으로 인한 고성능 컴퓨팅 시스템 덕분에 대규모 이미지와 비디오 인식 문제에서 성공가도를 달리고 있다. 특히,

### 2 설명

#### 2.1 아케텍쳐

모든 이미지는 224 x 224 로 들어갔으며 다른 전처리는 없었음. 대신 모든 RGB 평균값을 각 픽셀에서 빼긴 했음.

우리는 매우 작은 크기(상하좌우를 확인할 수 있는 최소 크기)의 3x3 필터(커널)를 사용함.

1x1 합성곱도 사용함.

스트라이드는 1 고정.

3x3 합성곱에서 패딩은 1임.

conv Layer 전부 맥스풀링을 사용하며 2x2 윈도우에 스트라이드는 2.

4096
4096
1000
softmax

모든 층은 ReLU를 사용함.

1층을 제외한 모든 층은 LRN 사용함. (loss는 줄여주지 않지만. 메모리 소비나 계산 시간이 줄어듬.)

#### 2.2 설정

Table1에 이 논문에서 평가된 값들이 명시되어 있음.

Table2에 각 설정에서 사용된 파라메터의 수들이 있음.

#### 2.3 고찰

우리의 모델은 2012, 2013년에 최고의 성능을 보여준 모델과 꽤 다르다.

#### 3.1 훈련(최적화)

SGD: The batch size was set to 256, momentum - 0.9. learning rate 0.01
weight decay - 0.0005
dropout - 0.5 / first two layers
