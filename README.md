# VGGNet
VGGNet 구현

## 논문 해석

### 초록

이 논문에서, 우리는 대량의 이미지를 다루는 이미지 분류 합성곱 신경망에서의 층의 깊이에 따른 영향에 대해 연구하였다. 우리의 주요 기여는 아주 작은 합성곱 필터를 사용하는 네트워크의 깊이를 점점 늘려 철저한 평가하는 것이며, 16 - 19 깊이의 층을 사용하여 이전 기술보다 확실한 개선을 보여준다. 이 발견은 우리의 2014 이미지넷 챌린지 제출 자료의 기초가 되었으며, 장소 분류 분야에서 1등, 사물 분류 분야에서 2등을 달성하였다. 우리는 우리의 결과물이 다른 데이터에도 일반화가 잘 되어 있다는 것을 보여주며, 최첨단의 결과물이다.

### 1. 서론

최근, 합성곱 계층은 대규모 공개 이미지 저장소 ImageNet나 GPU 클러스터링으로 인한 고성능 컴퓨팅 시스템 덕분에 대규모 이미지와 비디오 인식 문제에서 성공가도를 달리고 있다. 특히, ILSVRC가 몇 세대의 방대한 이미지 분류 시스템, 높은 차원의 얕은 특징 엔코딩의 실험대로써 깊은 시각 사물 인식 아키텍쳐의 발전에 중요한 역할을 해왔다.

합성곱 신경망이 컴퓨터 비전 분야에서 더 많이 사용됨과 동시에, (Krizhevsky et al)의 아키텍쳐에서 정확도를 개선하기 위한 몇몇의 시도가 있어왔다. 그 예시로, ILSVRC 2013에서 최고의 성능을 나타낸 결과물 (Zeiler & Fergus)은 첫 합성곱 신경망에서 더 작은 커널과 더 작은 스트라이드를 사용했다. 다른 예시로는 전체 이미지와 여러 스케일에서 더욱 촘촘하게 훈련하고 테스트하는 것에 대해 다루었습니다. 이 논문에서 우리는 합성곱 신경망에서 중요한 또 다른 측면을 다루려고 합니다. 바로 깊이입니다. 이를 위해, 아키텍쳐에서 다른 파라메터는 모두 고정하였고, 합성곱 신경망을 추가함으로써 신경망의 깊이를 꾸준히 늘려나갔으며, 모든 층에 걸쳐 아주 작은 합성곱 필터를 썼기에 가능했습니다.

그 결과로, 우리는 확실히 더 정확한 합성곱 신경망을 도출해냈으며, 단순히 ILSVRC 분류와 로컬라이제이션에서 최신의 정확도를 나타낼 뿐 아니라, 다른 이미지 데이터셋에도 적용 가능하며, 비교적 간단한 파이프라인으로써 사용되어도 완벽한 성능을 보여주었습니다. (예시: 세부 조정 없이 선형 SVM으로 분류된 Deep features). 우리는 추후 연구를 위해 최고 성능의 두 모델을 선보입니다.

### 2 설명

#### 2.1 아케텍쳐

모든 이미지는 224 x 224 로 들어갔으며 다른 전처리는 없었음. 대신 모든 RGB 평균값을 각 픽셀에서 빼긴 했음.

우리는 매우 작은 크기(상하좌우를 확인할 수 있는 최소 크기)의 3x3 필터(커널)를 사용함.

1x1 합성곱도 사용함.

스트라이드는 1 고정.

3x3 합성곱에서 패딩은 1임.

conv Layer 전부 맥스풀링을 사용하며 2x2 윈도우에 스트라이드는 2.

4096
4096
1000
softmax

모든 층은 ReLU를 사용함.

1층을 제외한 모든 층은 LRN 사용함. (loss는 줄여주지 않지만. 메모리 소비나 계산 시간이 줄어듬.)

#### 2.2 설정

Table1에 이 논문에서 평가된 값들이 명시되어 있음.

Table2에 각 설정에서 사용된 파라메터의 수들이 있음.

#### 2.3 고찰

우리의 모델은 2012, 2013년에 최고의 성능을 보여준 모델과 꽤 다르다.

#### 3.1 훈련(최적화)

SGD: The batch size was set to 256, momentum - 0.9. learning rate 0.01
weight decay - 0.0005
dropout - 0.5 / first two layers
